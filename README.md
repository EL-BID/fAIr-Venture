# fAIr-Venture

## Descripción:

<p align="justify"> La plantilla de Evaluación de Riesgos de Ética de Inteligencia Artificial (IA) o IA responsable para inversores ("fAIr Venture") es un instrumento desarrollado por BID Lab, el brazo de innovación y capital emprendedor del Grupo Banco Interamericano de Desarrollo ("BID"), a través de la iniciativa fAIr LAC+, la Universidad Adolfo Ibáñez y Magical Startups Chile, la cual está destinada a ayudar a los inversores a entender los riesgos no-financieros asociados a la tecnología de IA o aprendizaje automatizado desarrollada por las empresas en las que invierten. </p>

<p align="justify"> El instrumento conceptualiza los riesgos en tres grandes dimensiones descritas a continuación, con base en el marco analítico y guía para el análisis de la IA denominado fAIr LAC 3S: </p>

* **Solución**: El alineamiento con los fundamentos de la IA responsable y fiable de la solución desarrollada, así como aspectos relacionados con el modelo de negocio y su gobernanza.

* **Sistema**: Los medios técnicos requeridos para asegurar el alineamiento del sistema de IA con los principios de IA más comúnmente aceptados como los promovidos por la OCDE.

* **Sociedad**: El impacto en la sociedad que tiene la solución o producto basada en IA.

## ¿Qué hace el proyecto?

<p align="justify"> La herramienta fue elaborada en el marco del proyecto Algoritmos Éticos, Responsables y Transparentes, el cual fue una iniciativa multi-actor ejecutada por la Universidad Adolfo Ibañez (UAI), con apoyo de BID Lab, co-ejecutado por Magical Startups, y del cual son socios el Ministerio de Ciencias, Chile Compra, el Instituto de Previsión Social (IPS), el Fondo Nacional de Salud (Fonasa).</p>

<p align="justify"> Este proyecto instaló capacidades y estándares para incorporar consideraciones éticas en la compra y utilización de Inteligencia Artificial (IA) y algoritmos de decisión automatizada (ADA) en agencias estatales (vertical pública), y en la formulación y desarrollo de estas soluciones por parte de los proveedores tecnológicos e inversionistas (vertical privada), principalmente en Chile.</p>

<p align="justify"> En el marco de esta vertical privada, iniciamos la co-creación de una herramienta de IA Ética para que los fondos de Venture Capital (VC) puedan identificar oportunamente riesgos éticos asociados al desarrollo e implementación de tecnologías de IA en las startups que financian, y gestionar proactivamente dichos riesgos.</p>

## ¿Por qué es útil?

<p align="justify"> fAIr Venture ha sido diseñada con el fin de contribuir a la identificación de los principales riesgos éticos de la IA desarrollada por empresas del sector privado como startups. Esta herramienta pretende ser un instrumento de apoyo a la toma de decisiones en marcos más amplios de debida diligencia de los fondos de capital emprendedor y no pretende ofrecer o sustituir asesoría legal.</p>

<p align="justify"> Esta herramienta tampoco pretende informar a los inversores sobre si continuar o no con una operación de financiamiento a cualquier entidad.</p>

<p align="justify"> El objetivo es que los fondos de VC utilicen la herramienta en la evaluación de las startups en las cuales están considerando invertir, idealmente durante la exploración o la debida diligencia.</p>

<p align="justify"> La herramienta se alinea a las dimensiones del marco fAIr LAC 3S (Sociedad, Sistema y Solución) de BID Lab.</p>

* **Dimensión Sociedad**: Las preguntas en esta dimensión buscan entender los usuarios del sistema de IA y los grupos impactados por la tecnología, el grado de notificación que genera el sistema sobre la interacción con los usuarios y su potencial impacto negativo sobre áreas relevantes para el bienestar de los seres humanos, entre otras.

* **Dimensión Solución**: Las preguntas en esta dimensión buscan entender las áreas de aplicación y usos del sistema de IA, la criticidad de dichas actividades y el alcance de su despliegue, entre otras.

* **Dimensión Sistema**: Las preguntas en esta dimensión buscan entender aspectos específicos de la tecnología como las características de los datos insumo del modelo y de la base de datos de entrenamiento, la adopción de prácticas de evaluación de sesgos y de transparencia y explicabilidad, y el grado de autonomía del modelo, entre otras.

<p align="justify"> Contiene 21 preguntas cortas con opciones de respuesta predefinidas en su mayoría adaptadas y traducidas de OCDE (2022) Framework for the Classification of AI Systems, y asociadas a las características de sistemas de IA confiables propuestas por el National Institute of Science and Technology - NIST (2023) en su Artificial Intelligence Risk Management Framework.</p>

<p align="justify"> Cada opción de respuesta tiene un nivel de riesgo correspondiente, desde bajo hasta muy alto, que luego permite, a través de promedios simples, otorgar una calificación general del nivel de riesgo de la startup y un diagrama radial de las calificaciones de riesgo en las tres dimensiones.</p>

## Guía de usuario / ¿Cómo ocuparlo?

<p align="justify"> Para poder hacer uso de la herramienta, únicamente hay que descargar el archivo de Excel y seleccionar la opción correspondiente en cada una de las filas de la matriz.</p>

<p align="justify"> La tabla genera automáticamente una respuesta asociada al nivel de riesgo de la opción seleccionada de modo que el diagrama radial resultante genera según el usuario selecciona las opciones.</p>

<p align="justify"> La herramienta se alinea con las dimensiones del marco S3 (Sociedad, Sistema y Solución) de BID Lab, aquellas detallamos a continuación:</p>

**a) Dimensión sociedad:** En esta dimensión, las preguntas buscan comprender a los usuarios del sistema de IA y los grupos impactados por la tecnología. Se evalúa el grado de notificación que genera el sistema sobre la interacción con los usuarios y su potencial impacto negativo en áreas relevantes para el bienestar humano, entre otros aspectos.

**b) Dimensión Solución:** Las preguntas en esta dimensión buscan entender las áreas de aplicación y los usos del sistema de IA, así como la criticidad de las actividades relacionadas y el alcance de su despliegue, entre otros factores.

**c) Dimensión Sistema:** En esta dimensión, las preguntas se centran en aspectos técnicos de la tecnología, como las características de los datos de entrada del modelo y la base de datos de entrenamiento, la adopción de prácticas de evaluación de sesgos y de transparencia y explicabilidad, y el grado de autonomía del modelo, entre otros aspectos técnicos.  

**Preguntas y opciones de respuesta**

<p align="justify"> La herramienta contiene 21 preguntas cortas con opciones de respuesta predefinidas, en su mayoría adaptadas y traducidas del OCDE (2022) Framework for the Classification of AI Systems. Estas preguntas están asociadas a las características de sistemas de IA confiables propuestas por el National Institute of Science and Technology - NIST (2023) en su Artificial Intelligence Risk Management Framework.</p>

**Niveles de riesgo**

<p align="justify"> Cada opción de respuesta tiene un nivel de riesgo correspondiente, desde bajo hasta muy alto. Estos niveles de riesgo se utilizan para otorgar una calificación general del nivel de riesgo de la startup.</p>

**Diagrama radial**

<p align="justify"> Además de la calificación general, se genera un diagrama radial que muestra las calificaciones de riesgo en las tres dimensiones (Sociedad, Solución y Sistema). Esto proporciona una representación visual de los riesgos en cada área.</p>

<p align="justify"> Si bien la herramienta proporciona una experiencia de usuario y arroja promedios y un resultado gráfico, su aplicación puede ser flexible tomando solo algunas de las preguntas o ajustando las opciones de respuesta y sus niveles de riesgo para reflejar la realidad del VC y/o de sus startups. No obstante, el equipo del proyecto se encuentra evaluando alternativas para la maduración y escalamiento del proyecto que ayudarán a aclarar posibles casos de uso.</p>


## ¿Cómo contribuir?

<p align="justify"> Cuando descarga la herramienta podrá realizar adaptaciones, e integrarla o utilizarla dentro de sus proceso o sistemas internos, sin embargo, usted no puede usar el nombre, ninguna marca registrada, marca oficial, emblema oficial o logotipo del Grupo BID, de la Universidad o Magical, o cualquiera de sus otros medios de promoción o publicidad, sin el consentimiento previo por escrito del Grupo BID ni en cualquier evento para representar o implicar una asociación o afiliación con el Grupo BID.</p>

<p align="justify"> La herramienta fAIr Venture está licenciada bajo la licencia Creative Commons CC BY-SA 4 Atribución-Compartir-Igual 4.0 Internacional  disponible aquí:</p>

<p align="center"> https://creativecommons.org/licenses/by-sa/4.0/</p>

<p align="justify"> Conforme a esta licencia los usuarios están autorizados a :</p>

* **Compartir:** copiar y redistribuir el material en cualquier medio o formato para cualquier fin, incluso comercial.
* **Adaptar:** remezclar, transformar y desarrollar el material para cualquier propósito, incluso comercialmente.

Bajo los siguientes términos:
* **Atribución:** debe dar el crédito correspondiente, proporcionar un enlace a la licencia e indicar si se realizaron cambios. Puede hacerlo de cualquier manera razonable, pero no de ninguna manera que sugiera que el licenciante lo respalda a usted o su uso.
*  **Compartir Igual:** si se remezcla, transforma o se construye a partir del material, debes distribuir tus contribuciones bajo la misma licencia que el original.
*  **Sin restricciones adicionales:** no es posible aplicar términos legales ni medidas tecnológicas que restrinjan legalmente a otros hacer cualquier cosa que la licencia permite.

## ¿Quién mantiene el repositorio?

<p align="justify"> El repositorio es propiedad del Grupo BID (https://www.iadb.org/en) y este en particular se gestiona a través del laboratorio de innovación del Grupo, BID Lab (https://bidlab.org/en), a través de la iniciativa fAIr LAC+, cuyos mayores detalles se pueden consultar en: https://fairlac.iadb.org/</p>

## ¿Cómo citar el repositorio?

IDB Lab, fAIr LAC (2022). fAIr Venture. BID Data Github Repository

## Referencias

<p align="justify"> La coordinación del proceso de co-creación estuvo a cargo del equipo del proyecto Algoritmos Éticos con el trabajo de Juan Manuel Ramírez como consultor para la elaboración de la herramienta. Como parte del equipo de Algoritmos Éticos, el proyecto estuvo ideado y liderado por César Said Rosales Torres, Mara Balestrini, Tetsuro Narita y Carolina Carrasco (BID Lab), Maria Paz Hermosilla, Romina Garrido y Reinel Tabares (Universidad Adolfo Ibañez), Juan Orlandi, Teresita Saavedra y Vanessa Neble (Magical Startups), Marcos Maldonado (Ministerio de Ciencia - Chile) y Juan Manuel Ramírez (consultor del proyecto). Agradecemos por su tiempo y dedicación a Andrea Araneda y Paola Negrin (Fen Ventures), Sebastián Ibañez (Dadneo), Camila Petignat (The Yield Lab), Carolina Alarcón (Red Chile Global Ventures), Chris Thompson (Magical), Constanza Corvalán y Michelle Viscaino (Simbiótica) y Diego Borquez (Charly.io). Agradecemos por su tiempo y retroalimentación al equipo de BID Lab, en particular a Cesar Buenadicha y Gyoung Joo Choe.</p> 

<p align="justify"> El proceso de desarrollo de la Herramienta de IA Ética para VC “fAIr Venture” fue concebido desde el inicio como una co-creación con los usuarios objetivo, buscando entender sus prácticas actuales y expectativas, para maximizar su potencial adopción. En el proceso de co-creación participaron los siguientes actores clave:</p> 

-	Fen Ventures. 
-	Dadneo (Fondo Vulcano). 
-	Magical (Administradora de fondos de inversión)
-	The Yield Lab.
-	Chile Global Ventures (Fondo Clin).

<p align="justify"> Para iniciar el proceso, se elaboró una versión inicial de la herramienta partiendo de un referenciamiento de marcos, metodologías y herramientas existentes para analizar aspectos de IA Ética en VCs y startups. Ejemplos de estos marcos son:</p> 

-	BID Lab (2021). Auto-evaluación ética para el ecosistema emprendedor.
-	OCDE (2022). Framework for the Classification of AI Systems.
-	NIST (2023). Artificial Intelligence Risk Management Framework.
-	Dotan, R. (2022). Responsible Investment in AI. A Guidebook for VCs.
-	Harvard Kennedy School of Government. Belfer Center. Technology and Public Purpose Project

Una vez desarrollada la versión inicial, se llevó a cabo el siguiente proceso con los fondos participantes:
-	Entrevistas iniciales de entendimiento de los procesos de cada VC.
-	Sesión de trabajo conjunta para realizar una nivelación conceptual.
-	Sesiones de trabajo para revisar la primera versión de la herramienta y recibir feedback.
-	Pilotaje en un startup del portafolio de tres VCs: Fen Ventures, Dadneo y Magical.

<p align="justify">Este proceso mostró la acogida positiva de este tipo de herramientas aplicadas y la importancia de abrir una conversación alrededor de temas de IA Ética entre el VC y los startups. También ayudó a simplificar su contenido y condujo a aclarar conceptos para facilitar su adopción.</p>

## Limitación de responsabilidades

<p align="justify"> El acceso a fAIr Venture, y su uso de dicha herramienta será, "TAL CUAL" sin garantía expresa o implícita de ningún tipo y puede contener errores. Los creadores de la herramienta no dan ninguna representación o garantía de que la herramienta fAIr Venture y/o el resultado de la evaluación de riesgo funcionarán o se producirán sin errores. El uso de la herramienta fAIr Venture y sus resultados son responsabilidad del usuario. Los desarrolladores de esta herramienta no sonresponsable de los daños o gastos directos o indirectos, incidentales, o de cualquier tipo ocurridos por el uso de fAIr Venture.</p>

<p align="justify"> Tampoco se garantiza el acceso ininterrumpido a la herramienta fAIr Venture y sus actualizaciones. El acceso a la herramienta fAIr Venture puede verse interrumpido por motivos de mantenimiento programado, actualizaciones, para corregir errores, razones de seguridad u otras fuera del control razonable.</p>

<p align="justify">Se sugiere que el análisis lo realice el VC con base en la situación actual del startup y del sistema de IA, y no con base en estados futuros posibles. Esto permitirá tener una mirada más objetiva y facilitará la discusión. No obstante, si el VC decidiera invertir en la startup, la herramienta se podría aplicar en distintos momentos del tiempo y podría ayudar a monitorear el progreso en las distintas dimensiones.</p>

<p align="justify"> Se sugiere que los resultados de la herramienta no impliquen una decisión de inversión en la startup. Es decir, niveles altos de riesgo en la herramienta no necesariamente se deben traducir en una decisión de no inversión. Se propone que la herramienta sea un insumo para abrir una conversación informada entre VC y startup.
Se recomienda que durante el proceso de aplicación de la herramienta haya al menos un espacio de conversación entre el VC y la startup alrededor de las dimensiones y preguntas. En la experiencia del pilotaje identificamos que el debate y la reflexión pueden generar valor tanto para la startup como para el VC.</p>

<p align="justify"> Se considera que no es imperativo que los VC involucren personal especializado (desarrolladores, asesores o expertos en IA) para aplicar la herramienta. El ejercicio de pilotaje se realizó con Investment Officers (IO) de los fondos con resultados positivos. Sin embargo, un contexto general sobre sistemas de IA, sus riesgos y sus oportunidades, pueden ser de utilidad para sacar mejor provecho de este ejercicio.</p>

Recomendamos en particular estas dos guías para complementar el uso de esta herramienta: 

BID Lab (2021). Autoevaluación ética de IA para actores del ecosistema emprendedor: Guía de aplicación Disponible en: https://publications.iadb.org/es/autoevaluacion-etica-de-ia-para-actores-del-ecosistema-emprendedor-guia-de-aplicacion

World Economic Forum (2022). Empowering AI Leadership: AI C-Suite Toolkit. WEF. 

Queremos seguir mejorando y evolucionando la herramienta. Esta versión 1.0 se encuentra abierta a comentarios y recomendaciones. 
Para mayor información contacta a fairlac@iadb.org

La política general de uso de datos está disponible aquí: https://www.iadb.org/en/home/privacy-notice



